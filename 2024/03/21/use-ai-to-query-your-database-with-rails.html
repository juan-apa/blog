<!DOCTYPE html>
<html lang="en-US" class="dark">
  <head>
    <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-M7WF9Z88');</script>
<!-- End Google Tag Manager -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <title>Use Ai To Query Your Database With Rails - Juan Aparicio</title>
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax-highlight.css">

    <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;600;700&display=swap" rel="stylesheet">


    <link rel="favicon" href="/assets/images/favicon.ico">
<link rel="apple-touch-icon" sizes="180x180" href="/assets/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/images/favicon-16x16.png">
<link rel="manifest" href="/assets/site.webmanifest">

    <meta property="og:title" content="Use Ai To Query Your Database With Rails" />
<meta property="og:description" content="A Ruby and Rails developer's blog" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://juan-apa.xyz/2024/03/21/use-ai-to-query-your-database-with-rails.html" />

<!-- twitter og tags -->
<meta property="twitter:domain" content="juan-apa.xyz">
<meta property="twitter:url" content="https://juan-apa.xyz/2024/03/21/use-ai-to-query-your-database-with-rails.html">
<meta name="twitter:title" content="Use Ai To Query Your Database With Rails">
<meta name="twitter:description" content="A Ruby and Rails developer's blog">
<meta name="twitter:card" content="summary_large_image">

    <meta property="og:image" content="https://juan-apa.xyz/assets/og_images/2024-03-21-use-ai-to-query-your-database-with-rails.png" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />

  </head>
  <body class="dark:bg-neutral-800 dark:text-gray-100 bg-white text-gray-950 max-w-2xl m-auto font-mono min-h-screen flex flex-col">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-M7WF9Z88"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
    <nav class="">
  <ul class="flex p-4 h-full">
    <li><a href="/" class="text-lg font-bold hover:dark:bg-neutral-700 px-4 py-2">Juan Aparicio</a></li>
    <li class="grow"></li>
    <li><a href="/blog" class="text-lg font-bold hover:dark:bg-neutral-700 px-4 py-2 underline underline-neutral-200">Blog</a></li>
  </ul>
</nav>


    <header class="flex flex-col items-center justify-center py-16">
      <h1 class="text-4xl font-bold text-center">Use Ai To Query Your Database With Rails</h1>
      
        <p class="text-neutral-500 text-lg mt-2">March 21, 2024</p>
      
    </header>


    <div class="container mx-auto prose dark:prose-invert dark:text-gray-100 text-gray-950 pt-4 px-2 sm:px-0">
      <!-- Include LaTex support script -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<h1 id="scenario">Scenario</h1>
<p>Suppose you have a Ruby on Rails app, where users write and post articles. You want to enable the users to ask questions about all the articles in the database, get a response, and links to the most relevant articles.</p>

<p>Why not use Postgres full text search? Well, asking and answering questions is not the same as searching for keywords. Also, as good as full text search is, it is not as good as AI at understanding the meaning of the text. For example:</p>

<p>If a user asks:</p>
<blockquote>
  <p>Are humans great?</p>
</blockquote>

<p>And the database contains articles that mention:</p>
<blockquote>
  <p>People are awesome</p>
</blockquote>

<p>Then full text search fails to find the article, because it does not understand that “humans” and “people” are the same thing. The only word they have in common is “are”, and that’s not enough to make a good match.</p>

<h1 id="tools">Tools</h1>
<ul>
  <li>Ruby on Rails, it does not matter if it is an api only or a full stack app.</li>
  <li>Postgres</li>
  <li>Postgres pgvector extension</li>
  <li>OpenAI API key (or any other AI model that’s capable of generating embeddings)</li>
</ul>

<h1 id="the-plan">The Plan</h1>
<ol>
  <li>Create a migration that enables the pgvector extension in your database.</li>
  <li>Create a model to store the embeddings of your data, that belongs to a polymorphic <code class="language-plaintext highlighter-rouge">embeddable</code> model.</li>
  <li>Create a service object that will communicate with the OpenAI embeddings API, which will receive a text and return an embedding.</li>
  <li>Create an <code class="language-plaintext highlighter-rouge">Embeddable</code> model concern that will include the logic to generate the embeddings and store them in the database.</li>
  <li>Create a controller that will receive the user’s query, generate an embedding, and query the database for the most similar embeddings.</li>
</ol>

<p>Sounds simple, right?</p>

<p>If you are not familiar with the term embeddings, it may seem like some magic is going on, but in reality, there’s none.</p>

<h2 id="embeddings">Embeddings</h2>
<p>Given OpenAI’s own definition:</p>

<blockquote>
  <p>OpenAI’s text embeddings measure the relatedness of text strings</p>
</blockquote>

<p>Okay, that really explains what it does, but how does it even look like? How can we use it?</p>

<p>An embedding is nothing more than a vector of floating point numbers that represents how a text scores (field) in different aspects (dimensions)</p>

<h3 id="example">Example</h3>
<p>Given a method that given a text, it generates an embedding of 2 dimensions, where the first dimension represents how positive the text is, and the second dimension represents how much the text talks about cats.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @param input [String]</span>
<span class="c1"># @return [Array&lt;Float&gt;]</span>
<span class="k">def</span> <span class="nf">create_embedding</span><span class="p">(</span><span class="n">input</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">input</span><span class="p">.</span><span class="nf">match?</span><span class="p">(</span><span class="sr">/(like|love)/</span><span class="p">)</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="mf">1.0</span>
  <span class="k">else</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="k">end</span>

  <span class="k">if</span> <span class="n">input</span><span class="p">.</span><span class="nf">match?</span><span class="p">(</span><span class="sr">/(cats|cat|feline|furball)/</span><span class="p">)</span>
    <span class="n">cats</span> <span class="o">=</span> <span class="mf">1.0</span>
  <span class="k">else</span>
    <span class="n">cats</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="k">end</span>

  <span class="p">[</span><span class="n">positive</span><span class="p">,</span> <span class="n">cats</span><span class="p">]</span>
<span class="k">end</span>
</code></pre></div></div>
<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_embedding</span><span class="p">(</span><span class="s2">"I like cats"</span><span class="p">)</span> <span class="c1"># =&gt; [1.0, 1.0]</span>
</code></pre></div></div>

<p>In this example, the string <code class="language-plaintext highlighter-rouge">"I like cats"</code> is transformed into a vector of 2 dimensions.
If we were to create an embedding for the string <code class="language-plaintext highlighter-rouge">"I like dogs"</code>, we would get a different vector</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_embedding</span><span class="p">(</span><span class="s2">"I like dogs"</span><span class="p">)</span> <span class="c1"># =&gt; [1.0, 0.0]</span>
</code></pre></div></div>

<p>And if we were to create an embedding for a string with a very different meaning, we would get a very different vector</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_embedding</span><span class="p">(</span><span class="s2">"Mondays suck"</span><span class="p">)</span> <span class="c1"># =&gt; [0.0, 0.0]</span>
</code></pre></div></div>

<p>This is a very simple algorithm for creating embeddings that does not really use trained LLM’s, but it serves as a good example of what embeddings are and how they are generated.</p>

<h2 id="calculating-the-similarity-between-embeddings">Calculating the similarity between embeddings</h2>

<p>Now that we know how embeddings are generated, we can calculate the similarity between them.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s1">'bundler/inline'</span>

<span class="n">gemfile</span> <span class="k">do</span>
  <span class="n">source</span> <span class="s1">'https://rubygems.org'</span>
  <span class="n">gem</span> <span class="s1">'matplotlib'</span><span class="p">,</span> <span class="s1">'~&gt; 1.3.0'</span>
<span class="k">end</span>

<span class="nb">require</span> <span class="s1">'matplotlib/pyplot'</span>
<span class="n">plt</span> <span class="o">=</span> <span class="no">Matplotlib</span><span class="o">::</span><span class="no">Pyplot</span>

<span class="n">cats</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.238</span><span class="p">,</span> <span class="mf">0.839</span><span class="p">]</span>
<span class="n">dogs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.248</span><span class="p">,</span> <span class="mf">0.859</span><span class="p">]</span>
<span class="n">mondays</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.938</span><span class="p">,</span> <span class="mf">0.239</span><span class="p">]</span>

<span class="c1"># scatter plot</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">cats</span><span class="p">,</span> <span class="ss">color: </span><span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">dogs</span><span class="p">,</span> <span class="ss">color: </span><span class="s1">'g'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">mondays</span><span class="p">,</span> <span class="ss">color: </span><span class="s1">'b'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="s1">'cats'</span><span class="p">,</span> <span class="s1">'dogs'</span><span class="p">,</span> <span class="s1">'mondays'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>
<p>This will generate a plot that looks like this:
<img src="/assets/images/ai-query-db/cats-dogs-mondays-scatter.png" alt="Embeddings scatter plot" /></p>

<p>We can now see that the vectors for <code class="language-plaintext highlighter-rouge">"I like cats"</code> and <code class="language-plaintext highlighter-rouge">"I like dogs"</code> are very close to each other, while the vector for <code class="language-plaintext highlighter-rouge">"Mondays suck"</code> is very far from the other two.</p>

<h2 id="calculating-the-similarity-between-embeddings-1">Calculating the similarity between embeddings</h2>
<p>The way we can check if two embeddings are similar is by calculating the similarity between them. For doing this, we’ll use one of 2 methods: cosine similarity or euclidean distance.</p>

<h3 id="cosine-similarity">Cosine similarity</h3>
<p>Given Wikipedia’s definition:</p>
<blockquote>
  <p>[…] cosine similarity is a measure of similarity between two non-zero vectors defined in an inner product space. […]</p>
</blockquote>

<p>The cosine similarity between any two vectors is calculated as follows:</p>

\[\text{cosine_similarity} = \frac{A \cdot B}{\|A\| \times \|B\|}\]

<p>Where:</p>
<ul>
  <li>A and B are the non-zero vectors</li>
</ul>

<p>The <code class="language-plaintext highlighter-rouge">cosine_similarity</code> method in Ruby could look like this:</p>
<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @param a [Array&lt;Float&gt;]</span>
<span class="c1"># @param b [Array&lt;Float&gt;]</span>
<span class="c1"># @return [Float]</span>
<span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="n">dot_product</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">zip</span><span class="p">(</span><span class="n">b</span><span class="p">).</span><span class="nf">sum</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">|</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="p">}</span>
  <span class="n">magnitude_a</span> <span class="o">=</span> <span class="no">Math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="nf">sum</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="p">})</span>
  <span class="n">magnitude_b</span> <span class="o">=</span> <span class="no">Math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="nf">sum</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="p">})</span>
  <span class="n">dot_product</span> <span class="o">/</span> <span class="p">(</span><span class="n">magnitude_a</span> <span class="o">*</span> <span class="n">magnitude_b</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p>If we run this method with the vectors we created before, we would get the following results:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">cats</span><span class="p">,</span> <span class="n">dogs</span><span class="p">)</span> <span class="c1"># =&gt; 0.9999891633941651</span>
<span class="n">cosine_similarity</span><span class="p">(</span><span class="n">cats</span><span class="p">,</span> <span class="n">mondays</span><span class="p">)</span> <span class="c1"># =&gt; 0.5019901922103566</span>
<span class="n">cosine_similarity</span><span class="p">(</span><span class="n">dogs</span><span class="p">,</span> <span class="n">mondays</span><span class="p">)</span> <span class="c1"># =&gt; 0.5060111156140782</span>
</code></pre></div></div>

<p>As we can see, the cosine similarity between the vectors for <code class="language-plaintext highlighter-rouge">"I like cats"</code> and <code class="language-plaintext highlighter-rouge">"I like dogs"</code> is very close to 1, while the cosine similarity between the vectors for <code class="language-plaintext highlighter-rouge">"I like cats"</code> and <code class="language-plaintext highlighter-rouge">"Mondays suck"</code> is around 0.5</p>

<h3 id="euclidean-distance">Euclidean distance</h3>
<p>Given Wikipedia’s definition:</p>
<blockquote>
  <p>In mathematics, the Euclidean distance between two points in Euclidean space is the length of the line segment between them. […]</p>
</blockquote>

<p>The euclidean distance between any two vectors is calculated as follows:</p>

\[\text{euclidean_distance} = \sqrt{\sum_{i=1}^{n} (A_i - B_i)^2}\]

<p>Where:</p>
<ul>
  <li>A and B are the non-zero vectors</li>
</ul>

<p>The <code class="language-plaintext highlighter-rouge">euclidean_distance</code> method in Ruby could look like this:</p>
<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># @param a [Array&lt;Float&gt;]</span>
<span class="c1"># @param b [Array&lt;Float&gt;]</span>
<span class="c1"># @return [Float]</span>
<span class="k">def</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="no">Math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="nf">zip</span><span class="p">(</span><span class="n">b</span><span class="p">).</span><span class="nf">sum</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">|</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">})</span>
<span class="k">end</span>
</code></pre></div></div>

<p>If we run this method with the vectors we created before, we would get the following results:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">euclidean_distance</span><span class="p">(</span><span class="n">cats</span><span class="p">,</span> <span class="n">dogs</span><span class="p">)</span> <span class="c1"># =&gt; 0.022360679774997918</span>
<span class="n">euclidean_distance</span><span class="p">(</span><span class="n">cats</span><span class="p">,</span> <span class="n">mondays</span><span class="p">)</span> <span class="c1"># =&gt; 0.9219544457292886</span>
<span class="n">euclidean_distance</span><span class="p">(</span><span class="n">dogs</span><span class="p">,</span> <span class="n">mondays</span><span class="p">)</span> <span class="c1"># =&gt; 0.9276313923105448</span>
</code></pre></div></div>

<p>As we can see, the euclidean distance between the vectors for <code class="language-plaintext highlighter-rouge">"I like cats"</code> and <code class="language-plaintext highlighter-rouge">"I like dogs"</code> is very close to 0, while the euclidean distance between the vectors for <code class="language-plaintext highlighter-rouge">"I like cats"</code> and <code class="language-plaintext highlighter-rouge">"Mondays suck"</code> is around 1</p>

<p>This means, that the vectors for <code class="language-plaintext highlighter-rouge">"I like cats"</code> and <code class="language-plaintext highlighter-rouge">"I like dogs"</code> are very close to each other, while the vector for <code class="language-plaintext highlighter-rouge">"Mondays suck"</code> is very far from the other two.</p>

<h2 id="openai-embeddings">OpenAi embeddings</h2>
<p>OpenAI’s embeddings are a bit more complex than the simple example we’ve seen before, but the idea remains the same.</p>

<p>OpenAI’s embeddings generated by the <code class="language-plaintext highlighter-rouge">text-embedding-ada-002</code> model are <code class="language-plaintext highlighter-rouge">1536</code> dimensions long, and they are generated using a model that has been trained on a large dataset of text.</p>

<p>Each dimension in the vector represents a different aspect of the text, and the value of the dimension represents the importance of that aspect in the text.</p>

<p>However, the way we use the embeddings is the same as before, we will be sending a text to the OpenAI API, and it will return a <code class="language-plaintext highlighter-rouge">1536</code> dimensions long vector. After that, we can calculate the similarity between the vectors using the cosine similarity or the euclidean distance by using Postgres pgvector extension’s methods.</p>

<h1 id="show-me-the-code">Show me the code</h1>
<p>Now that we have a basic understanding of what embeddings are and how to calculate the similarity between them, let’s move on to the implementation.</p>

<h2 id="step-1-install-neighbor-gem">Step 1: Install neighbor gem</h2>
<p>The <a href="https://github.com/ankane/neighbor">neighbor</a> gem provides the rails tooling we need to query the database for the most similar vectors:</p>
<ul>
  <li>pgvector support</li>
  <li>ActiveRecord integration</li>
  <li>ActiveRecord scopes for nearest neighbor search using cosine similarity or euclidean distance</li>
</ul>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Gemfile</span>
<span class="n">gem</span> <span class="s1">'neighbor'</span>
</code></pre></div></div>

<p>Then run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rails generate neighbor:vector
rails db:migrate
</code></pre></div></div>

<h2 id="step-2-create-a-model-to-store-the-embeddings">Step 2: Create a model to store the embeddings</h2>
<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># db/migrate/20240321120000_create_embeddings.rb</span>
<span class="k">class</span> <span class="nc">CreateEmbeddings</span> <span class="o">&lt;</span> <span class="no">ActiveRecord</span><span class="o">::</span><span class="no">Migration</span><span class="p">[</span><span class="mf">6.1</span><span class="p">]</span>
  <span class="k">def</span> <span class="nf">change</span>
    <span class="n">create_table</span> <span class="ss">:embeddings</span> <span class="k">do</span> <span class="o">|</span><span class="n">t</span><span class="o">|</span>
      <span class="n">t</span><span class="p">.</span><span class="nf">references</span> <span class="ss">:embeddable</span><span class="p">,</span> <span class="ss">polymorphic: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">null: </span><span class="kp">false</span>
      <span class="n">t</span><span class="p">.</span><span class="nf">vector</span><span class="p">,</span> <span class="ss">:vector</span><span class="p">,</span> <span class="ss">limit: </span><span class="mi">1536</span><span class="p">,</span> <span class="ss">null: </span><span class="kp">false</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="k">class</span> <span class="nc">Embedding</span> <span class="o">&lt;</span> <span class="no">ApplicationRecord</span>
  <span class="n">belongs_to</span> <span class="ss">:embeddable</span><span class="p">,</span> <span class="ss">polymorphic: </span><span class="kp">true</span>

  <span class="n">validates</span> <span class="ss">:vector</span><span class="p">,</span> <span class="ss">presence: </span><span class="kp">true</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="step-3-create-a-service-object-to-communicate-with-the-openai-embeddings-api">Step 3: Create a service object to communicate with the OpenAI embeddings API</h2>
<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># app/services/open_ai/embeddings.rb</span>
<span class="nb">require</span> <span class="s1">'net/http'</span>

<span class="k">class</span> <span class="nc">OpenAi::Embeddings</span>
  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">api_key</span><span class="p">)</span>
    <span class="vi">@api_key</span> <span class="o">=</span> <span class="n">api_key</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nc">self</span><span class="o">.</span><span class="nf">call</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">new</span><span class="p">(</span><span class="no">ENV</span><span class="p">[</span><span class="s2">"OPENAI_API_KEY"</span><span class="p">]).</span><span class="nf">call</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="no">Net</span><span class="o">::</span><span class="no">HTTP</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span>
      <span class="no">URI</span><span class="p">(</span><span class="s2">"https://api.openai.com/v1/embeddings"</span><span class="p">),</span>
      <span class="p">{</span>
        <span class="ss">input: </span><span class="n">text</span><span class="p">,</span>
        <span class="ss">model: </span><span class="s2">"text-embedding-ada-002"</span>
      <span class="p">}.</span><span class="nf">to_json</span><span class="p">,</span>
      <span class="s2">"Authorization"</span> <span class="o">=&gt;</span> <span class="s2">"Bearer </span><span class="si">#{</span><span class="vi">@api_key</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
      <span class="s2">"Content-Type"</span> <span class="o">=&gt;</span> <span class="s2">"application/json"</span>
    <span class="p">)</span>

    <span class="no">JSON</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="nf">body</span><span class="p">)[</span><span class="s2">"data"</span><span class="p">].</span><span class="nf">first</span><span class="p">[</span><span class="s2">"embedding"</span><span class="p">]</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="step-4-create-an-embeddable-model-concern">Step 4: Create an <code class="language-plaintext highlighter-rouge">Embeddable</code> model concern</h2>
<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># app/models/concerns/embeddable.rb</span>
<span class="c1"># Usage:</span>
<span class="c1"># class Article &lt; ApplicationRecord</span>
<span class="c1">#   include Embeddable</span>
<span class="c1">#   embedding_for :content</span>
<span class="c1">#</span>
<span class="c1">#   def text</span>
<span class="c1">#     content</span>
<span class="c1">#   end</span>
<span class="c1"># end</span>
<span class="k">module</span> <span class="nn">Embeddable</span>
  <span class="kp">extend</span> <span class="no">ActiveSupport</span><span class="o">::</span><span class="no">Concern</span>

  <span class="n">included</span> <span class="k">do</span>
    <span class="n">has_one</span> <span class="ss">:embedding</span><span class="p">,</span> <span class="ss">as: :embeddable</span><span class="p">,</span> <span class="ss">dependent: :destroy</span>
    <span class="n">after_create_commit</span> <span class="ss">:create_embedding</span>
  <span class="k">end</span>

  <span class="n">class_methods</span> <span class="k">do</span>
    <span class="k">def</span> <span class="nf">embedding_for</span><span class="p">(</span><span class="n">column</span> <span class="o">=</span> <span class="ss">:text</span><span class="p">,</span> <span class="ss">generator: </span><span class="s2">"OpenAi::Embeddings"</span><span class="p">)</span>
      <span class="vi">@embedding_column</span> <span class="o">=</span> <span class="n">column</span>
      <span class="vi">@embedding_generator</span> <span class="o">=</span> <span class="n">klass</span>
    <span class="k">end</span>

    <span class="k">def</span> <span class="nf">embedding_generator</span>
      <span class="vi">@embedding_generator</span>
    <span class="k">end</span>

    <span class="k">def</span> <span class="nf">embedding_column</span>
      <span class="vi">@embedding_column</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">create_embedding</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="no">Embedding</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
      <span class="ss">embeddable: </span><span class="nb">self</span><span class="p">,</span>
      <span class="ss">vector: </span><span class="n">embedding_generator</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="n">embedding_text</span><span class="p">)</span>
    <span class="p">)</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">embedding_text</span>
    <span class="nb">send</span><span class="p">(</span><span class="n">embedding_column</span><span class="p">)</span>
  <span class="k">end</span>

  <span class="kp">private</span>

  <span class="k">def</span> <span class="nf">embedding_generator</span>
    <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">embedding_generator</span><span class="p">.</span><span class="nf">constantize</span><span class="p">.</span><span class="nf">new</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="step-5-create-a-controller-that-will-receive-the-users-query">Step 5: Create a controller that will receive the user’s query</h2>
<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># app/controllers/search_controller.rb</span>
<span class="k">class</span> <span class="nc">SearchController</span> <span class="o">&lt;</span> <span class="no">ApplicationController</span>
  <span class="k">def</span> <span class="nf">index</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="ss">:query</span><span class="p">]</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="no">OpenAi</span><span class="o">::</span><span class="no">Embeddings</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="no">Embedding</span><span class="p">.</span><span class="nf">nearest_neighbor</span><span class="p">(</span><span class="ss">:vector</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="ss">distance: </span><span class="s1">'cosine'</span><span class="p">).</span><span class="nf">limit</span><span class="p">(</span><span class="n">embeddings_limit</span><span class="p">)</span>
    <span class="vi">@results</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:embeddable</span><span class="p">)</span>

    <span class="n">respond_to</span> <span class="k">do</span> <span class="o">|</span><span class="nb">format</span><span class="o">|</span>
      <span class="nb">format</span><span class="p">.</span><span class="nf">json</span> <span class="p">{</span> <span class="n">render</span> <span class="ss">json: </span><span class="vi">@results</span><span class="p">.</span><span class="nf">to_json</span> <span class="p">}</span>
      <span class="nb">format</span><span class="p">.</span><span class="nf">html</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="kp">private</span>

  <span class="k">def</span> <span class="nf">embeddings_limit</span>
    <span class="vi">@embeddings_limit</span> <span class="o">||=</span> <span class="k">begin</span>
      <span class="n">unconstrained_limit</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="ss">:limit</span><span class="p">]</span> <span class="o">||</span> <span class="mi">10</span>
      <span class="p">[</span><span class="n">unconstrained_limit</span><span class="p">.</span><span class="nf">to_i</span><span class="p">,</span> <span class="mi">10</span><span class="p">].</span><span class="nf">min</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h1 id="taking-it-further">Taking it further</h1>
<p>You may want to take this a step further, and create a context from the most similar embeddings, and then use the context to generate a response to the user’s query.
To achieve this, you could use the <a href="https://platform.openai.com/docs/models/gpt-3-5-turbo">OpenAI GPT 3.5 Turbo</a> model.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># app/services/open_ai/completions.rb</span>
<span class="nb">require</span> <span class="s1">'net/http'</span>

<span class="k">class</span> <span class="nc">OpenAi::Completions</span>
  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">api_key</span><span class="p">)</span>
    <span class="vi">@api_key</span> <span class="o">=</span> <span class="n">api_key</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nc">self</span><span class="o">.</span><span class="nf">call</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="ss">context: </span><span class="s1">''</span><span class="p">)</span>
    <span class="n">new</span><span class="p">(</span><span class="no">ENV</span><span class="p">[</span><span class="s2">"OPENAI_API_KEY"</span><span class="p">]).</span><span class="nf">call</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="ss">context: </span><span class="n">context</span><span class="p">)</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span> <span class="ss">role: </span><span class="s1">'user'</span><span class="p">,</span> <span class="ss">content: </span><span class="n">prompt</span> <span class="p">}]</span>
    <span class="n">kwargs</span><span class="p">.</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">role</span><span class="p">,</span> <span class="n">content</span><span class="o">|</span>
      <span class="n">messages</span> <span class="o">&lt;&lt;</span> <span class="p">{</span> <span class="n">role</span><span class="p">:,</span> <span class="n">content</span><span class="p">:}</span>
    <span class="k">end</span>

    <span class="n">response</span> <span class="o">=</span> <span class="no">Net</span><span class="o">::</span><span class="no">HTTP</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span>
      <span class="no">URI</span><span class="p">(</span><span class="s2">"https://api.openai.com/v1/chat/completions"</span><span class="p">),</span>
      <span class="p">{</span>
        <span class="ss">model: </span><span class="s2">"gpt-3.5-turbo"</span><span class="p">,</span>
        <span class="ss">messages:
      </span><span class="p">}.</span><span class="nf">to_json</span><span class="p">,</span>
      <span class="s2">"Authorization "</span><span class="o">=&gt;</span> <span class="s2">"Bearer </span><span class="si">#{</span><span class="vi">@api_key</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
      <span class="s2">"Content-Type"</span> <span class="o">=&gt;</span> <span class="s2">"application/json"</span>
    <span class="p">)</span>

    <span class="no">JSON</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="nf">body</span><span class="p">)[</span><span class="s2">"choices"</span><span class="p">].</span><span class="nf">first</span><span class="p">[</span><span class="s2">"message"</span><span class="p">][</span><span class="s2">"content"</span><span class="p">]</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># app/controllers/search_controller.rb</span>
<span class="k">class</span> <span class="nc">SearchController</span> <span class="o">&lt;</span> <span class="no">ApplicationController</span>
  <span class="k">def</span> <span class="nf">index</span>
    <span class="c1"># get the user's query</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="ss">:query</span><span class="p">]</span>

    <span class="c1"># get the embedding for the user's query</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="no">OpenAi</span><span class="o">::</span><span class="no">Embeddings</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

    <span class="c1"># get the most similar embeddings from the database</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="no">Embedding</span><span class="p">.</span><span class="nf">nearest_neighbor</span><span class="p">(</span><span class="ss">:vector</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="ss">distance: </span><span class="s1">'cosine'</span><span class="p">).</span><span class="nf">limit</span><span class="p">(</span><span class="n">embeddings_limit</span><span class="p">)</span>

    <span class="c1"># get the results models from the most similar embeddings</span>
    <span class="vi">@results</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:embeddable</span><span class="p">)</span>

    <span class="c1"># Generate context from the most similar embeddings</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">generate_context</span><span class="p">(</span><span class="vi">@results</span><span class="p">)</span>

    <span class="c1"># Ask OpenAI for a completion</span>
    <span class="vi">@response</span> <span class="o">=</span> <span class="no">OpenAi</span><span class="o">::</span><span class="no">Completions</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="ss">system: </span><span class="n">context</span><span class="p">)</span>

    <span class="n">respond_to</span> <span class="k">do</span> <span class="o">|</span><span class="nb">format</span><span class="o">|</span>
      <span class="c1"># json response includes the results and the response</span>
      <span class="nb">format</span><span class="p">.</span><span class="nf">json</span> <span class="p">{</span> <span class="n">render</span> <span class="ss">json: </span><span class="p">{</span> <span class="ss">results: </span><span class="vi">@results</span><span class="p">.</span><span class="nf">to_json</span><span class="p">,</span> <span class="ss">response: </span><span class="vi">@response</span> <span class="p">}</span> <span class="p">}</span>
      <span class="nb">format</span><span class="p">.</span><span class="nf">html</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="kp">private</span>

  <span class="k">def</span> <span class="nf">generate_context</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="n">results</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:embedding_text</span><span class="p">).</span><span class="nf">join</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h1 id="conclusion">Conclusion</h1>
<p>By leveraging Postgres and the pgvector extension alongside OpenAI’s API, we’ve established a robust system for querying and analyzing user-generated content within our database in a way that’s both efficient and developer friendly.</p>

<p>You now have the tools needed to integrate an AI search feature in your Rails app, that leverages the data that is already in your database.</p>

    </div>

    <footer class="p-4 text-sm text-center mt-auto">
  <ul class="flex justify-center gap-x-2">
    <li class="">
      <a href="https://twitter.com/not_kombustor" class="">Twitter (<span class="border-b border-solid border-neutral-200">@not_kombustor</span>)</a>
    </li>
    <vl class="border-r-2 dark:border-gray-700 border-gray-200"></vl>
    <li class="">
      <a href="https://github.com/juan-apa" class="">GitHub (<span class="border-b border-solid border-neutral-200">@juan-apa</span>)</a>
    </li>
  </ul>
</footer>

  </body>
</html>
